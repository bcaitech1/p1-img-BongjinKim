{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "falling-mixer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filesystem      Size  Used Avail Use% Mounted on\n",
      "overlay          48G   36G  9.7G  79% /\n",
      "tmpfs            64M     0   64M   0% /dev\n",
      "tmpfs            30G     0   30G   0% /sys/fs/cgroup\n",
      "shm             1.0G  1.1M 1023M   1% /dev/shm\n",
      "/dev/xvda1       48G   36G  9.7G  79% /etc/hosts\n",
      "tmpfs            30G   12K   30G   1% /proc/driver/nvidia\n",
      "udev             30G     0   30G   0% /dev/nvidia1\n",
      "tmpfs            30G     0   30G   0% /proc/acpi\n",
      "tmpfs            30G     0   30G   0% /proc/scsi\n",
      "tmpfs            30G     0   30G   0% /sys/firmware\n"
     ]
    }
   ],
   "source": [
    "!df -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "tribal-consultation",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch==1.7.0\n",
      "  Downloading torch-1.7.0-cp37-cp37m-manylinux1_x86_64.whl (776.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 776.7 MB 3.7 kB/s eta 0:00:016   |▍                               | 10.2 MB 3.9 MB/s eta 0:03:15     |█                               | 22.7 MB 4.1 MB/s eta 0:03:03     |█                               | 23.9 MB 4.1 MB/s eta 0:03:03     |█                               | 25.4 MB 4.1 MB/s eta 0:03:02     |█▏                              | 28.3 MB 4.7 MB/s eta 0:02:40     |█▌                              | 35.7 MB 5.4 MB/s eta 0:02:17     |█▌                              | 36.9 MB 5.4 MB/s eta 0:02:16     |█▊                              | 41.5 MB 6.8 MB/s eta 0:01:49     |██                              | 48.0 MB 7.6 MB/s eta 0:01:36     |██                              | 49.2 MB 7.6 MB/s eta 0:01:36     |██▎                             | 54.6 MB 8.4 MB/s eta 0:01:26     |██▍                             | 56.8 MB 8.4 MB/s eta 0:01:26     |██▍                             | 57.2 MB 8.4 MB/s eta 0:01:26     |██▍                             | 58.2 MB 8.4 MB/s eta 0:01:26     |██▍                             | 59.1 MB 8.4 MB/s eta 0:01:26     |██▉                             | 68.7 MB 9.8 MB/s eta 0:01:13     |██▉                             | 69.2 MB 9.8 MB/s eta 0:01:13     |███                             | 74.4 MB 11.4 MB/s eta 0:01:02     |███▏                            | 75.5 MB 11.4 MB/s eta 0:01:02     |███▏                            | 76.2 MB 11.4 MB/s eta 0:01:02     |███▏                            | 76.8 MB 11.4 MB/s eta 0:01:02     |███▍                            | 81.8 MB 11.4 MB/s eta 0:01:02     |███▋                            | 87.2 MB 8.1 MB/s eta 0:01:26     |███▊                            | 89.3 MB 8.1 MB/s eta 0:01:26     |███▊                            | 91.5 MB 8.1 MB/s eta 0:01:26     |████▏                           | 102.2 MB 10.3 MB/s eta 0:01:06     |████▌                           | 108.1 MB 10.3 MB/s eta 0:01:05     |██████                          | 146.4 MB 25.3 MB/s eta 0:00:25     |██████▏                         | 148.7 MB 25.3 MB/s eta 0:00:25     |██████▏                         | 150.0 MB 25.3 MB/s eta 0:00:25     |██████▎                         | 152.4 MB 25.3 MB/s eta 0:00:25     |██████▊                         | 162.2 MB 24.0 MB/s eta 0:00:26     |███████                         | 171.9 MB 24.0 MB/s eta 0:00:26     |███████▌                        | 183.2 MB 23.7 MB/s eta 0:00:26     |███████▊                        | 186.8 MB 23.7 MB/s eta 0:00:25     |████████                        | 191.7 MB 23.7 MB/s eta 0:00:25     |████████                        | 194.1 MB 23.7 MB/s eta 0:00:25     |████████▏                       | 197.8 MB 23.7 MB/s eta 0:00:25     |██████████▎                     | 248.3 MB 29.7 MB/s eta 0:00:18     |██████████▉                     | 261.9 MB 28.1 MB/s eta 0:00:19     |███████████▌                    | 280.4 MB 25.9 MB/s eta 0:00:20     |████████████▎                   | 298.8 MB 25.9 MB/s eta 0:00:19     |███████████████                 | 365.2 MB 24.7 MB/s eta 0:00:17     |███████████████▏                | 368.9 MB 24.7 MB/s eta 0:00:17     |████████████████▏               | 391.3 MB 32.4 MB/s eta 0:00:12     |█████████████████▏              | 417.0 MB 28.7 MB/s eta 0:00:13     |█████████████████▉              | 433.1 MB 20.1 MB/s eta 0:00:18     |██████████████████▍             | 446.8 MB 24.1 MB/s eta 0:00:14     |███████████████████             | 461.6 MB 24.1 MB/s eta 0:00:14     |███████████████████▏            | 464.0 MB 24.1 MB/s eta 0:00:13     |███████████████████▍            | 471.4 MB 15.9 MB/s eta 0:00:20     |████████████████████▉           | 505.9 MB 14.3 MB/s eta 0:00:19     |█████████████████████           | 507.2 MB 14.3 MB/s eta 0:00:19     |█████████████████████           | 509.6 MB 14.3 MB/s eta 0:00:19     |█████████████████████           | 510.9 MB 14.3 MB/s eta 0:00:19     |█████████████████████▏          | 513.3 MB 14.3 MB/s eta 0:00:19     |██████████████████████          | 534.3 MB 21.9 MB/s eta 0:00:12     |██████████████████████▏         | 538.1 MB 21.9 MB/s eta 0:00:11     |█████████████████████████▌      | 620.1 MB 3.3 MB/s eta 0:00:49     |██████████████████████████      | 632.4 MB 3.3 MB/s eta 0:00:45     |█████████████████████████████▊  | 721.4 MB 5.1 MB/s eta 0:00:11     |█████████████████████████████▉  | 723.8 MB 5.1 MB/s eta 0:00:11     |██████████████████████████████▎ | 736.2 MB 5.6 MB/s eta 0:00:08     |███████████████████████████████ | 753.8 MB 5.6 MB/s eta 0:00:05     |███████████████████████████████▌| 763.3 MB 6.1 MB/s eta 0:00:03     |████████████████████████████████| 775.7 MB 6.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting torchvision==0.8.0\n",
      "  Downloading torchvision-0.8.0-cp37-cp37m-manylinux1_x86_64.whl (11.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 11.8 MB 47.3 MB/s eta 0:00:01    |███▋                            | 1.3 MB 47.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: tensorboard==2.4.1 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 3)) (2.4.1)\n",
      "Requirement already satisfied: pandas==1.1.5 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 4)) (1.1.5)\n",
      "Requirement already satisfied: opencv-python==4.5.1.48 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 5)) (4.5.1.48)\n",
      "Requirement already satisfied: scikit-learn~=0.24.1 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 6)) (0.24.1)\n",
      "Requirement already satisfied: matplotlib==3.2.1 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 7)) (3.2.1)\n",
      "Collecting dataclasses\n",
      "  Downloading dataclasses-0.6-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torch==1.7.0->-r requirements.txt (line 1)) (1.18.5)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch==1.7.0->-r requirements.txt (line 1)) (3.7.4.3)\n",
      "Requirement already satisfied: future in /opt/conda/lib/python3.7/site-packages (from torch==1.7.0->-r requirements.txt (line 1)) (0.18.2)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /opt/conda/lib/python3.7/site-packages (from torchvision==0.8.0->-r requirements.txt (line 2)) (7.2.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard==2.4.1->-r requirements.txt (line 3)) (2.23.0)\n",
      "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /opt/conda/lib/python3.7/site-packages (from tensorboard==2.4.1->-r requirements.txt (line 3)) (0.34.2)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard==2.4.1->-r requirements.txt (line 3)) (1.8.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard==2.4.1->-r requirements.txt (line 3)) (46.4.0.post20200518)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /opt/conda/lib/python3.7/site-packages (from tensorboard==2.4.1->-r requirements.txt (line 3)) (1.28.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.7/site-packages (from tensorboard==2.4.1->-r requirements.txt (line 3)) (0.4.3)\n",
      "Requirement already satisfied: absl-py>=0.4 in /opt/conda/lib/python3.7/site-packages (from tensorboard==2.4.1->-r requirements.txt (line 3)) (0.12.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /opt/conda/lib/python3.7/site-packages (from tensorboard==2.4.1->-r requirements.txt (line 3)) (1.0.1)\n",
      "Requirement already satisfied: protobuf>=3.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard==2.4.1->-r requirements.txt (line 3)) (3.15.6)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.7/site-packages (from tensorboard==2.4.1->-r requirements.txt (line 3)) (3.3.4)\n",
      "Requirement already satisfied: six>=1.10.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard==2.4.1->-r requirements.txt (line 3)) (1.14.0)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in /opt/conda/lib/python3.7/site-packages (from tensorboard==2.4.1->-r requirements.txt (line 3)) (1.36.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas==1.1.5->-r requirements.txt (line 4)) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /opt/conda/lib/python3.7/site-packages (from pandas==1.1.5->-r requirements.txt (line 4)) (2020.1)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from scikit-learn~=0.24.1->-r requirements.txt (line 6)) (1.0.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn~=0.24.1->-r requirements.txt (line 6)) (2.1.0)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /opt/conda/lib/python3.7/site-packages (from scikit-learn~=0.24.1->-r requirements.txt (line 6)) (1.6.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib==3.2.1->-r requirements.txt (line 7)) (1.3.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib==3.2.1->-r requirements.txt (line 7)) (2.4.7)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib==3.2.1->-r requirements.txt (line 7)) (0.10.0)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard==2.4.1->-r requirements.txt (line 3)) (1.25.8)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard==2.4.1->-r requirements.txt (line 3)) (2.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard==2.4.1->-r requirements.txt (line 3)) (2020.6.20)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard==2.4.1->-r requirements.txt (line 3)) (3.0.4)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard==2.4.1->-r requirements.txt (line 3)) (4.7.2)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard==2.4.1->-r requirements.txt (line 3)) (4.2.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard==2.4.1->-r requirements.txt (line 3)) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard==2.4.1->-r requirements.txt (line 3)) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /opt/conda/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard==2.4.1->-r requirements.txt (line 3)) (3.9.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /opt/conda/lib/python3.7/site-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<2,>=1.6.3->tensorboard==2.4.1->-r requirements.txt (line 3)) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard==2.4.1->-r requirements.txt (line 3)) (3.1.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard==2.4.1->-r requirements.txt (line 3)) (3.4.1)\n",
      "Installing collected packages: dataclasses, torch, torchvision\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 1.6.0\n",
      "    Uninstalling torch-1.6.0:\n",
      "      Successfully uninstalled torch-1.6.0\n",
      "  Attempting uninstall: torchvision\n",
      "    Found existing installation: torchvision 0.7.0\n",
      "    Uninstalling torchvision-0.7.0:\n",
      "      Successfully uninstalled torchvision-0.7.0\n",
      "Successfully installed dataclasses-0.6 torch-1.7.0 torchvision-0.8.0\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "continent-tamil",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbongjinkim\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    }
   ],
   "source": [
    "#auth\n",
    "#202258dfa5f936da1bb79c4dd5f6d4b5d972e12a\n",
    "!wandb login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "printable-record",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: 4ie4ew68\n",
      "Sweep URL: https://wandb.ai/bongjinkim/efficientnet-sweeps2/sweeps/4ie4ew68\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 64hqozst with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \taccumulation_steps: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \taugmentation: MaskAugmentation\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcriterion: cross_entropy\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_dir: /opt/ml/input/data/train/images\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdataset: MaskSplitByProfileDataset\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfile: export\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfocal_gamma: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.003002449944031731\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlog_interval: 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel_dir: /opt/ml/model\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel_name: efficientnet-b4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_sample: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: SGDP\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tresize: [224, 224]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler: cosinelr\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tseed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalid_batch_size: 200\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbongjinkim\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mstoic-sweep-1\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/bongjinkim/efficientnet-sweeps2\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🧹 View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/bongjinkim/efficientnet-sweeps2/sweeps/4ie4ew68\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/bongjinkim/efficientnet-sweeps2/runs/64hqozst\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in /opt/ml/wandb/run-20210408_095401-64hqozst\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb offline` to turn off syncing.\n",
      "\n",
      "signal only works in main thread\n",
      "데이터 셋을 불러옵니다...\n",
      "모델을 불러옵니다.\n",
      "Loaded pretrained weights for efficientnet-b4\n",
      "loss를 정의합니다.\n",
      "Epoch[0/1](20/472) || f1-score 0.051 || training loss 2.88 || training accuracy 7.81% || lr 0.0030024 || \n",
      "Epoch[0/1](40/472) || f1-score 0.11 || training loss 2.726 || training accuracy 17.81% || lr 0.0030024 || \n",
      "Epoch[0/1](60/472) || f1-score 0.31 || training loss 2.569 || training accuracy 28.75% || lr 0.0030024 || \n",
      "Epoch[0/1](80/472) || f1-score 0.36 || training loss 2.371 || training accuracy 34.38% || lr 0.0030024 || \n",
      "Epoch[0/1](100/472) || f1-score 0.37 || training loss 2.03 || training accuracy 48.91% || lr 0.0030024 || \n",
      "Epoch[0/1](120/472) || f1-score 0.34 || training loss 1.735 || training accuracy 51.41% || lr 0.0030024 || \n",
      "Epoch[0/1](140/472) || f1-score 0.33 || training loss 1.606 || training accuracy 55.16% || lr 0.0030024 || \n",
      "Epoch[0/1](160/472) || f1-score 0.37 || training loss 1.273 || training accuracy 58.28% || lr 0.0030024 || \n",
      "Epoch[0/1](180/472) || f1-score 0.44 || training loss 1.266 || training accuracy 60.62% || lr 0.0030024 || \n",
      "Epoch[0/1](200/472) || f1-score 0.36 || training loss 1.177 || training accuracy 65.31% || lr 0.0030024 || \n",
      "Epoch[0/1](220/472) || f1-score 0.49 || training loss 1.12 || training accuracy 65.94% || lr 0.0030024 || \n",
      "Epoch[0/1](240/472) || f1-score  0.4 || training loss 1.05 || training accuracy 66.25% || lr 0.0030024 || \n",
      "Epoch[0/1](260/472) || f1-score 0.42 || training loss 0.8699 || training accuracy 70.62% || lr 0.0030024 || \n",
      "Epoch[0/1](280/472) || f1-score 0.69 || training loss 0.8716 || training accuracy 71.09% || lr 0.0030024 || \n",
      "Epoch[0/1](300/472) || f1-score 0.45 || training loss 0.8319 || training accuracy 68.75% || lr 0.0030024 || \n",
      "Epoch[0/1](320/472) || f1-score 0.52 || training loss 0.8133 || training accuracy 72.66% || lr 0.0030024 || \n",
      "Epoch[0/1](340/472) || f1-score 0.44 || training loss 0.8867 || training accuracy 75.00% || lr 0.0030024 || \n",
      "Epoch[0/1](360/472) || f1-score 0.61 || training loss 0.7155 || training accuracy 76.56% || lr 0.0030024 || \n",
      "Epoch[0/1](380/472) || f1-score 0.58 || training loss 0.7741 || training accuracy 73.28% || lr 0.0030024 || \n",
      "Epoch[0/1](400/472) || f1-score 0.37 || training loss 0.7087 || training accuracy 73.59% || lr 0.0030024 || \n",
      "Epoch[0/1](420/472) || f1-score 0.45 || training loss 0.7633 || training accuracy 75.62% || lr 0.0030024 || \n",
      "Epoch[0/1](440/472) || f1-score 0.63 || training loss 0.6708 || training accuracy 77.97% || lr 0.0030024 || \n",
      "Epoch[0/1](460/472) || f1-score 0.65 || training loss 0.6978 || training accuracy 77.03% || lr 0.0030024 || \n",
      "Calculating validation results...\n",
      "New best model for f1 score : 79.44%! saving the best model..\n",
      "[Val] f1-score: 0.73, acc : 79.44%, loss: 0.59 || best f1: 0.73, best acc : 79.44%, best loss: 0.59 \n",
      "\n",
      "모델을 불러옵니다.\n",
      "Loaded pretrained weights for efficientnet-b4\n",
      "loss를 정의합니다.\n",
      "Epoch[0/1](20/472) || f1-score 0.042 || training loss 2.891 || training accuracy 6.25% || lr 0.0030024 || \n",
      "Epoch[0/1](40/472) || f1-score 0.34 || training loss 2.743 || training accuracy 18.44% || lr 0.0030024 || \n",
      "Epoch[0/1](60/472) || f1-score 0.16 || training loss 2.554 || training accuracy 27.03% || lr 0.0030024 || \n",
      "Epoch[0/1](80/472) || f1-score 0.32 || training loss 2.34 || training accuracy 37.50% || lr 0.0030024 || \n",
      "Epoch[0/1](100/472) || f1-score 0.29 || training loss 2.056 || training accuracy 43.28% || lr 0.0030024 || \n",
      "Epoch[0/1](120/472) || f1-score 0.23 || training loss 1.74 || training accuracy 52.97% || lr 0.0030024 || \n",
      "Epoch[0/1](140/472) || f1-score 0.48 || training loss 1.509 || training accuracy 58.28% || lr 0.0030024 || \n",
      "Epoch[0/1](160/472) || f1-score 0.32 || training loss 1.306 || training accuracy 59.53% || lr 0.0030024 || \n",
      "Epoch[0/1](180/472) || f1-score 0.46 || training loss 1.185 || training accuracy 64.69% || lr 0.0030024 || \n",
      "Epoch[0/1](200/472) || f1-score 0.33 || training loss 1.115 || training accuracy 61.09% || lr 0.0030024 || \n",
      "Epoch[0/1](220/472) || f1-score 0.38 || training loss 1.035 || training accuracy 66.88% || lr 0.0030024 || \n",
      "Epoch[0/1](240/472) || f1-score 0.34 || training loss 0.9332 || training accuracy 70.00% || lr 0.0030024 || \n",
      "Epoch[0/1](260/472) || f1-score 0.34 || training loss 0.9193 || training accuracy 68.91% || lr 0.0030024 || \n",
      "Epoch[0/1](280/472) || f1-score 0.38 || training loss 0.931 || training accuracy 68.75% || lr 0.0030024 || \n",
      "Epoch[0/1](300/472) || f1-score 0.52 || training loss 0.8104 || training accuracy 70.00% || lr 0.0030024 || \n",
      "Epoch[0/1](320/472) || f1-score 0.33 || training loss 0.8489 || training accuracy 73.91% || lr 0.0030024 || \n",
      "Epoch[0/1](340/472) || f1-score 0.54 || training loss 0.7761 || training accuracy 74.38% || lr 0.0030024 || \n",
      "Epoch[0/1](360/472) || f1-score 0.63 || training loss 0.8174 || training accuracy 72.97% || lr 0.0030024 || \n",
      "Epoch[0/1](380/472) || f1-score 0.53 || training loss 0.7911 || training accuracy 74.38% || lr 0.0030024 || \n",
      "Epoch[0/1](400/472) || f1-score 0.65 || training loss 0.7082 || training accuracy 75.78% || lr 0.0030024 || \n",
      "Epoch[0/1](420/472) || f1-score 0.46 || training loss 0.6862 || training accuracy 76.56% || lr 0.0030024 || \n",
      "Epoch[0/1](440/472) || f1-score 0.56 || training loss 0.7039 || training accuracy 75.31% || lr 0.0030024 || \n",
      "Epoch[0/1](460/472) || f1-score 0.42 || training loss 0.6978 || training accuracy 74.06% || lr 0.0030024 || \n",
      "Calculating validation results...\n",
      "[Val] f1-score: 0.53, acc : 72.17%, loss: 0.63 || best f1: 0.73, best acc : 79.44%, best loss: 0.59 \n",
      "\n",
      "모델을 불러옵니다.\n",
      "Loaded pretrained weights for efficientnet-b4\n",
      "loss를 정의합니다.\n",
      "Epoch[0/1](20/472) || f1-score 0.024 || training loss 2.867 || training accuracy 6.88% || lr 0.0030024 || \n",
      "Epoch[0/1](40/472) || f1-score 0.079 || training loss 2.744 || training accuracy 18.59% || lr 0.0030024 || \n",
      "Epoch[0/1](60/472) || f1-score 0.17 || training loss 2.591 || training accuracy 24.38% || lr 0.0030024 || \n",
      "Epoch[0/1](80/472) || f1-score 0.23 || training loss 2.298 || training accuracy 35.62% || lr 0.0030024 || \n",
      "Epoch[0/1](100/472) || f1-score 0.34 || training loss 2.051 || training accuracy 44.06% || lr 0.0030024 || \n",
      "Epoch[0/1](120/472) || f1-score 0.44 || training loss 1.758 || training accuracy 52.97% || lr 0.0030024 || \n",
      "Epoch[0/1](140/472) || f1-score 0.46 || training loss 1.57 || training accuracy 55.00% || lr 0.0030024 || \n",
      "Epoch[0/1](160/472) || f1-score  0.4 || training loss 1.335 || training accuracy 58.13% || lr 0.0030024 || \n",
      "Epoch[0/1](180/472) || f1-score 0.32 || training loss 1.215 || training accuracy 60.16% || lr 0.0030024 || \n",
      "Epoch[0/1](200/472) || f1-score 0.35 || training loss 1.057 || training accuracy 67.66% || lr 0.0030024 || \n",
      "Epoch[0/1](220/472) || f1-score 0.32 || training loss 0.9948 || training accuracy 69.22% || lr 0.0030024 || \n",
      "Epoch[0/1](240/472) || f1-score 0.22 || training loss 0.9622 || training accuracy 68.44% || lr 0.0030024 || \n",
      "Epoch[0/1](260/472) || f1-score 0.45 || training loss 0.9288 || training accuracy 72.34% || lr 0.0030024 || \n",
      "Epoch[0/1](280/472) || f1-score 0.45 || training loss 0.9095 || training accuracy 72.97% || lr 0.0030024 || \n",
      "Epoch[0/1](300/472) || f1-score 0.31 || training loss 0.8321 || training accuracy 70.31% || lr 0.0030024 || \n",
      "Epoch[0/1](320/472) || f1-score 0.32 || training loss 0.7936 || training accuracy 71.72% || lr 0.0030024 || \n",
      "Epoch[0/1](340/472) || f1-score 0.37 || training loss 0.7769 || training accuracy 75.16% || lr 0.0030024 || \n",
      "Epoch[0/1](360/472) || f1-score 0.49 || training loss 0.7502 || training accuracy 70.31% || lr 0.0030024 || \n",
      "Epoch[0/1](380/472) || f1-score 0.51 || training loss 0.7607 || training accuracy 76.56% || lr 0.0030024 || \n",
      "Epoch[0/1](400/472) || f1-score 0.46 || training loss 0.7866 || training accuracy 72.97% || lr 0.0030024 || \n",
      "Epoch[0/1](420/472) || f1-score 0.58 || training loss 0.7495 || training accuracy 73.12% || lr 0.0030024 || \n",
      "Epoch[0/1](440/472) || f1-score 0.66 || training loss 0.7173 || training accuracy 74.38% || lr 0.0030024 || \n",
      "Epoch[0/1](460/472) || f1-score 0.72 || training loss 0.6698 || training accuracy 79.22% || lr 0.0030024 || \n",
      "Calculating validation results...\n",
      "[Val] f1-score: 0.66, acc : 74.34%, loss: 0.63 || best f1: 0.73, best acc : 79.44%, best loss: 0.59 \n",
      "\n",
      "모델을 불러옵니다.\n",
      "Loaded pretrained weights for efficientnet-b4\n",
      "loss를 정의합니다.\n",
      "Epoch[0/1](20/472) || f1-score 0.026 || training loss 2.887 || training accuracy 7.19% || lr 0.0030024 || \n",
      "Epoch[0/1](40/472) || f1-score 0.068 || training loss 2.735 || training accuracy 16.09% || lr 0.0030024 || \n",
      "Epoch[0/1](60/472) || f1-score 0.21 || training loss 2.54 || training accuracy 27.19% || lr 0.0030024 || \n",
      "Epoch[0/1](80/472) || f1-score 0.37 || training loss 2.232 || training accuracy 41.72% || lr 0.0030024 || \n",
      "Epoch[0/1](100/472) || f1-score 0.43 || training loss 1.969 || training accuracy 45.94% || lr 0.0030024 || \n",
      "Epoch[0/1](120/472) || f1-score 0.29 || training loss 1.726 || training accuracy 51.41% || lr 0.0030024 || \n",
      "Epoch[0/1](140/472) || f1-score 0.21 || training loss 1.473 || training accuracy 51.72% || lr 0.0030024 || \n",
      "Epoch[0/1](160/472) || f1-score 0.24 || training loss 1.329 || training accuracy 61.41% || lr 0.0030024 || \n",
      "Epoch[0/1](180/472) || f1-score  0.4 || training loss 1.178 || training accuracy 64.22% || lr 0.0030024 || \n",
      "Epoch[0/1](200/472) || f1-score 0.43 || training loss  1.1 || training accuracy 66.56% || lr 0.0030024 || \n",
      "Epoch[0/1](220/472) || f1-score 0.31 || training loss 1.009 || training accuracy 65.47% || lr 0.0030024 || \n",
      "Epoch[0/1](240/472) || f1-score 0.43 || training loss 1.003 || training accuracy 68.91% || lr 0.0030024 || \n",
      "Epoch[0/1](260/472) || f1-score 0.28 || training loss 0.9239 || training accuracy 69.38% || lr 0.0030024 || \n",
      "Epoch[0/1](280/472) || f1-score 0.58 || training loss 0.8262 || training accuracy 73.59% || lr 0.0030024 || \n",
      "Epoch[0/1](300/472) || f1-score 0.45 || training loss 0.8391 || training accuracy 73.28% || lr 0.0030024 || \n",
      "Epoch[0/1](320/472) || f1-score 0.47 || training loss 0.8757 || training accuracy 72.34% || lr 0.0030024 || \n",
      "Epoch[0/1](340/472) || f1-score 0.66 || training loss 0.8699 || training accuracy 72.19% || lr 0.0030024 || \n",
      "Epoch[0/1](360/472) || f1-score 0.36 || training loss 0.7626 || training accuracy 73.44% || lr 0.0030024 || \n",
      "Epoch[0/1](380/472) || f1-score 0.52 || training loss 0.7292 || training accuracy 75.16% || lr 0.0030024 || \n",
      "Epoch[0/1](400/472) || f1-score  0.5 || training loss 0.822 || training accuracy 74.38% || lr 0.0030024 || \n",
      "Epoch[0/1](420/472) || f1-score 0.45 || training loss 0.6968 || training accuracy 77.66% || lr 0.0030024 || \n",
      "Epoch[0/1](440/472) || f1-score 0.51 || training loss 0.7021 || training accuracy 77.97% || lr 0.0030024 || \n",
      "Epoch[0/1](460/472) || f1-score 0.53 || training loss 0.7217 || training accuracy 77.03% || lr 0.0030024 || \n",
      "Calculating validation results...\n",
      "[Val] f1-score: 0.53, acc : 72.38%, loss: 0.62 || best f1: 0.73, best acc : 79.44%, best loss: 0.59 \n",
      "\n",
      "모델을 불러옵니다.\n",
      "Loaded pretrained weights for efficientnet-b4\n",
      "loss를 정의합니다.\n",
      "Epoch[0/1](20/472) || f1-score 0.13 || training loss 2.874 || training accuracy 7.34% || lr 0.0030024 || \n",
      "Epoch[0/1](40/472) || f1-score 0.054 || training loss 2.739 || training accuracy 20.31% || lr 0.0030024 || \n",
      "Epoch[0/1](60/472) || f1-score 0.17 || training loss 2.573 || training accuracy 26.88% || lr 0.0030024 || \n",
      "Epoch[0/1](80/472) || f1-score 0.27 || training loss 2.298 || training accuracy 37.81% || lr 0.0030024 || \n",
      "Epoch[0/1](100/472) || f1-score 0.14 || training loss 2.073 || training accuracy 41.72% || lr 0.0030024 || \n",
      "Epoch[0/1](120/472) || f1-score 0.33 || training loss 1.801 || training accuracy 50.62% || lr 0.0030024 || \n",
      "Epoch[0/1](140/472) || f1-score 0.48 || training loss 1.511 || training accuracy 58.28% || lr 0.0030024 || \n",
      "Epoch[0/1](160/472) || f1-score 0.49 || training loss 1.407 || training accuracy 58.91% || lr 0.0030024 || \n",
      "Epoch[0/1](180/472) || f1-score  0.5 || training loss 1.227 || training accuracy 65.31% || lr 0.0030024 || \n",
      "Epoch[0/1](200/472) || f1-score 0.31 || training loss 1.042 || training accuracy 68.28% || lr 0.0030024 || \n",
      "Epoch[0/1](220/472) || f1-score 0.53 || training loss 0.9863 || training accuracy 67.19% || lr 0.0030024 || \n",
      "Epoch[0/1](240/472) || f1-score 0.63 || training loss 0.9523 || training accuracy 69.06% || lr 0.0030024 || \n",
      "Epoch[0/1](260/472) || f1-score 0.46 || training loss 0.8133 || training accuracy 72.97% || lr 0.0030024 || \n",
      "Epoch[0/1](280/472) || f1-score  0.3 || training loss 0.8268 || training accuracy 69.69% || lr 0.0030024 || \n",
      "Epoch[0/1](300/472) || f1-score 0.61 || training loss 0.7444 || training accuracy 74.22% || lr 0.0030024 || \n",
      "Epoch[0/1](320/472) || f1-score  0.4 || training loss 0.8008 || training accuracy 72.50% || lr 0.0030024 || \n",
      "Epoch[0/1](340/472) || f1-score 0.59 || training loss 0.7797 || training accuracy 72.81% || lr 0.0030024 || \n",
      "Epoch[0/1](360/472) || f1-score 0.59 || training loss 0.7655 || training accuracy 74.84% || lr 0.0030024 || \n",
      "Epoch[0/1](380/472) || f1-score 0.42 || training loss 0.7394 || training accuracy 74.22% || lr 0.0030024 || \n",
      "Epoch[0/1](400/472) || f1-score 0.54 || training loss 0.7587 || training accuracy 73.44% || lr 0.0030024 || \n",
      "Epoch[0/1](420/472) || f1-score 0.47 || training loss 0.7499 || training accuracy 75.31% || lr 0.0030024 || \n",
      "Epoch[0/1](440/472) || f1-score 0.41 || training loss 0.6365 || training accuracy 79.53% || lr 0.0030024 || \n",
      "Epoch[0/1](460/472) || f1-score 0.26 || training loss 0.7575 || training accuracy 71.72% || lr 0.0030024 || \n",
      "Calculating validation results...\n",
      "[Val] f1-score:  0.6, acc : 73.23%, loss: 0.68 || best f1: 0.73, best acc : 79.44%, best loss: 0.59 \n",
      "\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 31080\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Program ended successfully.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: /opt/ml/wandb/run-20210408_095401-64hqozst/logs/debug.log\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: /opt/ml/wandb/run-20210408_095401-64hqozst/logs/debug-internal.log\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   train_loss 0.75753\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    train_acc 0.71719\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     f1-score 0.25708\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     _runtime 1891\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   _timestamp 1617877532\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        _step 119\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     val_loss 0.67843\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      val_acc 0.73228\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_f1 0.60224\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   train_loss █▇▄▃▂▁▁▁█▆▄▂▂▂▁▁█▆▄▂▂▁▁▁█▅▃▂▂▂▁▁█▅▃▂▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    train_acc ▁▃▅▆▇▇██▁▄▆▆▇███▁▄▆▇▇▇██▂▅▆▇▇▇██▂▄▆▇▇▇█▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     f1-score ▁▄▄▆▅▆▇▆▁▄▆▄▄▄█▆▁▃▆▅▆▄▆█▁▅▃▅▄▆▆▆▁▂▆▇▄▇▇▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     _runtime ▁▁▁▂▂▂▂▃▃▃▃▃▃▃▃▄▄▄▄▄▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   _timestamp ▁▁▁▂▂▂▂▃▃▃▃▃▃▃▃▄▄▄▄▄▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        _step ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     val_loss ▁▄▄▄█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      val_acc █▁▃▁▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_f1 █▁▆▁▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mstoic-sweep-1\u001b[0m: \u001b[34mhttps://wandb.ai/bongjinkim/efficientnet-sweeps2/runs/64hqozst\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python train.py --file export --seed 42 --augmentation MaskAugmentation --valid_batch_size 200 --model_name efficientnet-b4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "economic-objective",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측을 시작합니다.\n",
      "Loaded pretrained weights for efficientnet-b4\n",
      "Traceback (most recent call last):\n",
      "  File \"inference.py\", line 97, in <module>\n",
      "    inference(data_dir, model_dir, output_dir, args)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/autograd/grad_mode.py\", line 26, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"inference.py\", line 37, in inference\n",
      "    model = load_model(\"MyModel\",model_dir, device, k_model).to(device)\n",
      "  File \"inference.py\", line 22, in load_model\n",
      "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/serialization.py\", line 581, in load\n",
      "    with _open_file_like(f, 'rb') as opened_file:\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/serialization.py\", line 230, in _open_file_like\n",
      "    return _open_file(name_or_buffer, mode)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/serialization.py\", line 211, in __init__\n",
      "    super(_open_file, self).__init__(open(name, mode))\n",
      "FileNotFoundError: [Errno 2] No such file or directory: './model/export9/best_0.7732804232804232.pth'\n"
     ]
    }
   ],
   "source": [
    "!python inference.py --model_name efficientnet-b4 --model_dir ./model/export9/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "auburn-solomon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"url\":\"https://prod-aistages-private.s3.amazonaws.com/\",\"fields\":{\"key\":\"app/Competitions/000001/Users/00000033/Submissions/0026/output.csv\",\"x-amz-algorithm\":\"AWS4-HMAC-SHA256\",\"x-amz-credential\":\"AKIA45LU4MHUJ7WLDQVO/20210408/ap-northeast-2/s3/aws4_request\",\"x-amz-date\":\"20210408T102539Z\",\"policy\":\"eyJleHBpcmF0aW9uIjogIjIwMjEtMDQtMDhUMTE6MjU6MzlaIiwgImNvbmRpdGlvbnMiOiBbeyJidWNrZXQiOiAicHJvZC1haXN0YWdlcy1wcml2YXRlIn0sIHsia2V5IjogImFwcC9Db21wZXRpdGlvbnMvMDAwMDAxL1VzZXJzLzAwMDAwMDMzL1N1Ym1pc3Npb25zLzAwMjYvb3V0cHV0LmNzdiJ9LCB7IngtYW16LWFsZ29yaXRobSI6ICJBV1M0LUhNQUMtU0hBMjU2In0sIHsieC1hbXotY3JlZGVudGlhbCI6ICJBS0lBNDVMVTRNSFVKN1dMRFFWTy8yMDIxMDQwOC9hcC1ub3J0aGVhc3QtMi9zMy9hd3M0X3JlcXVlc3QifSwgeyJ4LWFtei1kYXRlIjogIjIwMjEwNDA4VDEwMjUzOVoifV19\",\"x-amz-signature\":\"3ac232e31a5d10073b972598632cd5ee92296936e5a04ac48ead00c2ca9aff14\"},\"submission\":{\"id\":6946,\"phase\":\"Created\",\"type\":\"File\",\"local_id\":26,\"hyperparameters\":\"{\\\"training\\\": {}, \\\"inference\\\": {}}\",\"description\":\"\",\"final\":false,\"created_at\":\"2021-04-08T19:25:39.695497+09:00\",\"updated_at\":\"2021-04-08T19:25:39.695527+09:00\",\"user\":33,\"competition\":1,\"image\":null}}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import requests\n",
    "import os\n",
    "def submit(user_key='', file_path = ''):\n",
    "    if not user_key:\n",
    "        raise Exception(\"No UserKey\" )\n",
    "    url = 'http://ec2-13-124-161-225.ap-northeast-2.compute.amazonaws.com:8000/api/v1/competition/1/presigned_url/?description=&hyperparameters={%22training%22:{},%22inference%22:{}}'\n",
    "    headers = {\n",
    "        'Authorization': user_key\n",
    "    }\n",
    "    res = requests.get(url, headers=headers)\n",
    "    print(res.text)\n",
    "    data = json.loads(res.text)\n",
    "    \n",
    "    submit_url = data['url']\n",
    "    body = {\n",
    "        'key':'app/Competitions/000001/Users/{}/Submissions/{}/output.csv'.format(str(data['submission']['user']).zfill(8),str(data['submission']['local_id']).zfill(4)),\n",
    "        'x-amz-algorithm':data['fields']['x-amz-algorithm'],\n",
    "        'x-amz-credential':data['fields']['x-amz-credential'],\n",
    "        'x-amz-date':data['fields']['x-amz-date'],\n",
    "        'policy':data['fields']['policy'],\n",
    "        'x-amz-signature':data['fields']['x-amz-signature']\n",
    "    }\n",
    "    requests.post(url=submit_url, data=body, files={'file': open(file_path, 'rb')})\n",
    "\n",
    "submit(\"Bearer 0fdbed1f585d373faa764fd5a27e1752da997bda\", os.path.join(\"./output\", 'output.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "unlike-burning",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18G\t.\n",
      "13G\t./model\n",
      "3.1G\t./.cache\n",
      "1.7G\t./nni\n",
      "939M\t./input\n",
      "13M\t./wandb\n",
      "11M\t./venv\n",
      "996K\t./.local\n",
      "776K\t./.ipython\n",
      "588K\t./output\n",
      "116K\t./.ipynb_checkpoints\n",
      "40K\t./.jupyter\n",
      "32K\t./__pycache__\n",
      "20K\t./code\n",
      "16K\t./.config\n",
      "12K\t./overview\n",
      "8.0K\t./.nv\n",
      "8.0K\t./.conda\n",
      "4.0K\t./.empty\n"
     ]
    }
   ],
   "source": [
    "!du -h --max-depth=1 | sort -hr "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "motivated-monroe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove './.local/share/Trash/files': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "rm -r ./.local/share/Trash/files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "advised-stable",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
      "Requirement already satisfied: torch==1.7.1+cu101 in /opt/conda/lib/python3.7/site-packages (1.7.1+cu101)\n",
      "Requirement already satisfied: torchvision==0.8.2+cu101 in /opt/conda/lib/python3.7/site-packages (0.8.2+cu101)\n",
      "Requirement already satisfied: torchaudio==0.7.2 in /opt/conda/lib/python3.7/site-packages (0.7.2)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch==1.7.1+cu101) (3.7.4.3)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torch==1.7.1+cu101) (1.18.5)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /opt/conda/lib/python3.7/site-packages (from torchvision==0.8.2+cu101) (7.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch==1.7.1+cu101 torchvision==0.8.2+cu101 torchaudio==0.7.2 -f https://download.pytorch.org/whl/torch_stable.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}